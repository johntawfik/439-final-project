{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  movieId  rating  timestamp\n",
      "55        1     1031     5.0  964982653\n",
      "230       1     4006     4.0  964982903\n",
      "69        1     1197     5.0  964981872\n",
      "168       1     2596     5.0  964981144\n",
      "109       1     1777     4.0  964981230\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_user(ratings, test_size=0.2):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Get all unique users\n",
    "    for user_id in ratings['userId'].unique():\n",
    "        # Filter the dataset to include only rows corresponding to curr user\n",
    "        user_data = ratings[ratings['userId'] == user_id]\n",
    "        # Check if user has rated more than 5 movies to meaningfully split data into train and test\n",
    "        # Ex. user with 10 ratings -> 8 train, 2 test, but user with 3 ratings -> 2 train, 1 test\n",
    "            # In the latter case, we would not have enough data to train the model\n",
    "        # If user has rated more than 5 movies, split the data into train and test\n",
    "        # Else, include all data in train\n",
    "        if len(user_data) >= 5:\n",
    "            train_data, test_data = train_test_split(user_data, test_size=test_size, random_state=42)\n",
    "            train_list.append(train_data)\n",
    "            test_list.append(test_data)\n",
    "        else:\n",
    "            train_list.append(user_data)\n",
    "    \n",
    "    # Combine training and testing data for all users into train and test\n",
    "    train = pd.concat(train_list)\n",
    "    test = pd.concat(test_list)\n",
    "    return train, test\n",
    "\n",
    "train_data, test_data = train_test_split_user(ratings)\n",
    "print(train_data.head())\n",
    "# We don't need timestamp column\n",
    "train_data = train_data.drop(columns=['timestamp'])\n",
    "test_data = test_data.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize(ratings):\n",
    "    # Group by userId\n",
    "    normalized_ratings = ratings.groupby('userId')['rating'].transform(lambda x: quantile_scale(x))\n",
    "    ratings['rating'] = normalized_ratings\n",
    "    return ratings\n",
    "\n",
    "def quantile_scale(ratings):\n",
    "    # Sort ratings and assign ranks\n",
    "    sorted_ratings = np.sort(ratings)\n",
    "    ranks = np.argsort(np.argsort(ratings))  # Get ranks of the original ratings\n",
    "    # Assign the sorted values to original ranks (quantile transformation)\n",
    "    return np.interp(ratings, sorted_ratings, sorted_ratings)\n",
    "train_data = quantile_normalize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['weight'] = train_data.groupby('movieId')['movieId'].transform('count')\n",
    "train_data['weight'] = train_data['weight'] / train_data['weight'].sum()  # Normalize weights\n",
    "train_data = train_data.sample(frac=1, weights=train_data['weight'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_movies = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_movies)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_movies)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            print(\"Iteration: %d ; mae = %.4f ; rmse = %.4f\" % (i+1, self.mae(), self.rmse()))\n",
    "          \n",
    "    def mae(self):\n",
    "        xs, ys = self.R.nonzero() \n",
    "        predicted = self.full_matrix()  \n",
    "        error = 0\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            error += abs(self.R[x, y] - predicted[x, y])  \n",
    "        \n",
    "        return error / len(xs)\n",
    "    \n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "\n",
    "        return np.sqrt(error/len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            P_i = self.P[i, :].copy()\n",
    "            Q_j = self.Q[j, :].copy()\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * Q_j - self.beta * P_i)\n",
    "            self.Q[j, :] += self.alpha * (e * P_i - self.beta * Q_j)\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        m_b = self.b_i[j] if j < len(self.b_i) else 0\n",
    "        l_i = self.Q[j, :].T if j < len(self.Q) else np.mean(self.Q, axis=0) \n",
    "        prediction = self.b + self.b_u[i] + m_b + self.P[i, :].dot(l_i)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 ; mae = 0.7012 ; rmse = 0.8992\n",
      "Iteration: 2 ; mae = 0.6778 ; rmse = 0.8752\n",
      "Iteration: 3 ; mae = 0.6664 ; rmse = 0.8621\n",
      "Iteration: 4 ; mae = 0.6572 ; rmse = 0.8532\n",
      "Iteration: 5 ; mae = 0.6520 ; rmse = 0.8459\n",
      "Iteration: 6 ; mae = 0.6473 ; rmse = 0.8404\n",
      "Iteration: 7 ; mae = 0.6439 ; rmse = 0.8356\n",
      "Iteration: 8 ; mae = 0.6405 ; rmse = 0.8311\n",
      "Iteration: 9 ; mae = 0.6370 ; rmse = 0.8272\n",
      "Iteration: 10 ; mae = 0.6338 ; rmse = 0.8238\n",
      "Iteration: 11 ; mae = 0.6320 ; rmse = 0.8206\n",
      "Iteration: 12 ; mae = 0.6286 ; rmse = 0.8174\n",
      "Iteration: 13 ; mae = 0.6259 ; rmse = 0.8138\n",
      "Iteration: 14 ; mae = 0.6239 ; rmse = 0.8106\n",
      "Iteration: 15 ; mae = 0.6214 ; rmse = 0.8068\n",
      "Iteration: 16 ; mae = 0.6181 ; rmse = 0.8026\n",
      "Iteration: 17 ; mae = 0.6144 ; rmse = 0.7981\n",
      "Iteration: 18 ; mae = 0.6104 ; rmse = 0.7926\n",
      "Iteration: 19 ; mae = 0.6067 ; rmse = 0.7867\n",
      "Iteration: 20 ; mae = 0.6018 ; rmse = 0.7798\n",
      "Iteration: 21 ; mae = 0.5955 ; rmse = 0.7715\n",
      "Iteration: 22 ; mae = 0.5890 ; rmse = 0.7631\n",
      "Iteration: 23 ; mae = 0.5823 ; rmse = 0.7535\n",
      "Iteration: 24 ; mae = 0.5746 ; rmse = 0.7433\n",
      "Iteration: 25 ; mae = 0.5670 ; rmse = 0.7325\n",
      "Iteration: 26 ; mae = 0.5584 ; rmse = 0.7209\n",
      "Iteration: 27 ; mae = 0.5494 ; rmse = 0.7090\n",
      "Iteration: 28 ; mae = 0.5402 ; rmse = 0.6972\n",
      "Iteration: 29 ; mae = 0.5315 ; rmse = 0.6848\n",
      "Iteration: 30 ; mae = 0.5222 ; rmse = 0.6726\n",
      "Iteration: 31 ; mae = 0.5132 ; rmse = 0.6602\n",
      "Iteration: 32 ; mae = 0.5035 ; rmse = 0.6480\n",
      "Iteration: 33 ; mae = 0.4942 ; rmse = 0.6357\n",
      "Iteration: 34 ; mae = 0.4852 ; rmse = 0.6239\n",
      "Iteration: 35 ; mae = 0.4767 ; rmse = 0.6127\n",
      "Iteration: 36 ; mae = 0.4672 ; rmse = 0.6006\n",
      "Iteration: 37 ; mae = 0.4587 ; rmse = 0.5897\n",
      "Iteration: 38 ; mae = 0.4502 ; rmse = 0.5787\n",
      "Iteration: 39 ; mae = 0.4422 ; rmse = 0.5681\n",
      "Iteration: 40 ; mae = 0.4340 ; rmse = 0.5578\n",
      "Iteration: 41 ; mae = 0.4272 ; rmse = 0.5481\n",
      "Iteration: 42 ; mae = 0.4196 ; rmse = 0.5386\n",
      "Iteration: 43 ; mae = 0.4124 ; rmse = 0.5297\n",
      "Iteration: 44 ; mae = 0.4056 ; rmse = 0.5207\n",
      "Iteration: 45 ; mae = 0.3985 ; rmse = 0.5120\n",
      "Iteration: 46 ; mae = 0.3926 ; rmse = 0.5039\n",
      "Iteration: 47 ; mae = 0.3861 ; rmse = 0.4959\n",
      "Iteration: 48 ; mae = 0.3805 ; rmse = 0.4883\n",
      "Iteration: 49 ; mae = 0.3744 ; rmse = 0.4809\n",
      "Iteration: 50 ; mae = 0.3688 ; rmse = 0.4737\n",
      "Iteration: 51 ; mae = 0.3638 ; rmse = 0.4672\n",
      "Iteration: 52 ; mae = 0.3588 ; rmse = 0.4609\n",
      "Iteration: 53 ; mae = 0.3536 ; rmse = 0.4547\n",
      "Iteration: 54 ; mae = 0.3490 ; rmse = 0.4489\n",
      "Iteration: 55 ; mae = 0.3446 ; rmse = 0.4431\n",
      "Iteration: 56 ; mae = 0.3402 ; rmse = 0.4375\n",
      "Iteration: 57 ; mae = 0.3361 ; rmse = 0.4325\n",
      "Iteration: 58 ; mae = 0.3318 ; rmse = 0.4273\n",
      "Iteration: 59 ; mae = 0.3285 ; rmse = 0.4229\n",
      "Iteration: 60 ; mae = 0.3243 ; rmse = 0.4181\n",
      "Iteration: 61 ; mae = 0.3211 ; rmse = 0.4139\n",
      "Iteration: 62 ; mae = 0.3173 ; rmse = 0.4092\n",
      "Iteration: 63 ; mae = 0.3142 ; rmse = 0.4055\n",
      "Iteration: 64 ; mae = 0.3110 ; rmse = 0.4017\n",
      "Iteration: 65 ; mae = 0.3082 ; rmse = 0.3981\n",
      "Iteration: 66 ; mae = 0.3052 ; rmse = 0.3944\n",
      "Iteration: 67 ; mae = 0.3020 ; rmse = 0.3907\n",
      "Iteration: 68 ; mae = 0.2995 ; rmse = 0.3875\n",
      "Iteration: 69 ; mae = 0.2972 ; rmse = 0.3845\n",
      "Iteration: 70 ; mae = 0.2942 ; rmse = 0.3811\n"
     ]
    }
   ],
   "source": [
    "user_ids = train_data['userId'].unique()  \n",
    "movie_ids = train_data['movieId'].unique()  \n",
    "\n",
    "user_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "movie_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "R = np.zeros((len(user_ids), len(movie_ids)))\n",
    "\n",
    "for row in train_data.itertuples():\n",
    "    user_idx = user_to_idx[row.userId]\n",
    "    movie_idx = movie_to_idx[row.movieId]\n",
    "    R[user_idx, movie_idx] = row.rating\n",
    "\n",
    "mf = MF(R, K=50, alpha=0.01, beta=0.05, iterations=70)\n",
    "# Iteration: 178 ; mae = 0.1979 ; rmse = 0.2732\n",
    "\n",
    "mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(mf_model, test_data, user_to_idx, movie_to_idx):\n",
    "    squared_error = 0\n",
    "    absolute_error = 0\n",
    "    n = len(test_data)\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        uid = int(row['userId'])\n",
    "        mid = int(row['movieId'])\n",
    "             \n",
    "        user_id = int(user_to_idx[uid])\n",
    "        movie_id = int(movie_to_idx[mid]) if mid in movie_to_idx else len(movie_to_idx)\n",
    "        actual_rating = row['rating']\n",
    "        \n",
    "        predicted_rating = mf_model.get_rating(user_id, movie_id)\n",
    "        \n",
    "        squared_error += (actual_rating - predicted_rating) ** 2\n",
    "        \n",
    "        absolute_error += abs(actual_rating - predicted_rating)\n",
    "    \n",
    "    rmse = np.sqrt(squared_error / n)\n",
    "    mae = absolute_error / n\n",
    "\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8611403600424232\n",
      "Test MAE: 0.6592161081145493\n"
     ]
    }
   ],
   "source": [
    "rmse, mae = test_model(mf, test_data, user_to_idx, movie_to_idx)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwatched_movies(ratings):\n",
    "    all_movie_ids = set(ratings['movieId'])\n",
    "    user_to_unwatched_movies = {}\n",
    "\n",
    "    for user_id in ratings['userId'].unique():\n",
    "        user = ratings[ratings['userId'] == user_id]\n",
    "        watched_movies = set(user['movieId'])\n",
    "        unwatched_movies = all_movie_ids - watched_movies\n",
    "        user_to_unwatched_movies[user_id] = unwatched_movies\n",
    "\n",
    "    return user_to_unwatched_movies\n",
    "\n",
    "def recommend_movies(mf_model, user_to_idx, movie_to_idx, n=10):\n",
    "    unwatched = unwatched_movies(train_data)\n",
    "    recommendations = {}\n",
    "\n",
    "    for user_id in user_to_idx.keys():\n",
    "        user_idx = user_to_idx[user_id]\n",
    "        predictions = mf_model.full_matrix()[user_idx]\n",
    "        recommended_movie_idxs = np.argsort(predictions)[::-1]\n",
    "        recommended_movies = [k for k, v in movie_to_idx.items() if v in recommended_movie_idxs and k in unwatched[user_id]][:n]\n",
    "        recommendations[user_id] = recommended_movies\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "def enhanced_recommend_movies(mf_model, user_to_idx, movie_to_idx, train_data, n=10, \n",
    "                           rating_threshold=3.5, min_ratings=10):\n",
    "    \"\"\"\n",
    "    Enhanced recommendation function with multiple improvements:\n",
    "    1. Considers movie popularity and rating distribution\n",
    "    2. Filters out movies with too few ratings\n",
    "    3. Uses rating threshold to determine \"liked\" movies\n",
    "    4. Implements candidate selection\n",
    "    \"\"\"\n",
    "    # Calculate movie statistics\n",
    "    movie_stats = train_data.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean', 'std']\n",
    "    }).droplevel(0, axis=1)\n",
    "    \n",
    "    # Filter movies with enough ratings\n",
    "    valid_movies = set(movie_stats[movie_stats['count'] >= min_ratings].index)\n",
    "    \n",
    "    # Calculate user preferences\n",
    "    user_preferences = {}\n",
    "    for user_id in train_data['userId'].unique():\n",
    "        user_ratings = train_data[train_data['userId'] == user_id]\n",
    "        liked_movies = user_ratings[user_ratings['rating'] >= rating_threshold]['movieId']\n",
    "        \n",
    "        if len(liked_movies) > 0:\n",
    "            # Get genres or other features of liked movies\n",
    "            user_preferences[user_id] = liked_movies.tolist()\n",
    "    \n",
    "    unwatched = unwatched_movies(train_data)\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in user_to_idx.keys():\n",
    "        if user_id not in user_preferences:\n",
    "            continue\n",
    "            \n",
    "        user_idx = user_to_idx[user_id]\n",
    "        user_unwatched = unwatched[user_id].intersection(valid_movies)\n",
    "        \n",
    "        if not user_unwatched:\n",
    "            continue\n",
    "            \n",
    "        # Get predictions for unwatched movies\n",
    "        predictions = []\n",
    "        for movie_id in user_unwatched:\n",
    "            if movie_id in movie_to_idx:\n",
    "                movie_idx = movie_to_idx[movie_id]\n",
    "                pred_rating = mf_model.get_rating(user_idx, movie_idx)\n",
    "                \n",
    "                # Calculate confidence score based on number of ratings\n",
    "                confidence = 1 - (1 / (1 + movie_stats.loc[movie_id, 'count'] / 100))\n",
    "                \n",
    "                # Calculate popularity score normalized between 0 and 1\n",
    "                popularity = movie_stats.loc[movie_id, 'count'] / movie_stats['count'].max()\n",
    "                \n",
    "                # Combine prediction with confidence and popularity\n",
    "                adjusted_score = (0.7 * pred_rating + \n",
    "                                0.2 * confidence + \n",
    "                                0.1 * popularity)\n",
    "                \n",
    "                predictions.append((movie_id, adjusted_score))\n",
    "        \n",
    "        # Sort by adjusted score and get top N\n",
    "        recommendations[user_id] = [\n",
    "            movie_id for movie_id, _ in \n",
    "            sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "        ]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "top_10_recommendations = enhanced_recommend_movies(mf, user_to_idx, movie_to_idx, train_data, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision \t8.9327%\n",
      "Recall \t\t4.1164%\n",
      "F-Measure \t5.6357%\n",
      "NDCG \t\t0.0260\n"
     ]
    }
   ],
   "source": [
    "def dcg(recommended_movies, actual_movies):\n",
    "    dcg_value = 0.0\n",
    "    for i, movie in enumerate(recommended_movies):\n",
    "        if movie in actual_movies:\n",
    "            dcg_value += 1 / np.log2(i + 2)  \n",
    "    return dcg_value\n",
    "\n",
    "def idcg(actual_movies, length):\n",
    "    idcg_value = 0.0\n",
    "    for i in range(min(len(actual_movies), length)):\n",
    "        idcg_value += 1 / np.log2(i + 2)\n",
    "    return idcg_value\n",
    "\n",
    "def recommendation_performance(recommendations, test_data):\n",
    "    running_precision, running_recall, running_ndcg = 0, 0, 0\n",
    "\n",
    "    for user_id, recommended_movies in recommendations.items():\n",
    "        actual_movies = test_data[test_data['userId'] == user_id]['movieId']\n",
    "\n",
    "        intersection = len(set(recommended_movies) & set(actual_movies))\n",
    "        precision = (intersection / len(recommended_movies)) * 100\n",
    "        recall = (intersection / len(actual_movies)) * 100\n",
    "\n",
    "        running_precision += precision\n",
    "        running_recall += recall\n",
    "\n",
    "        dcg_value = dcg(recommended_movies, actual_movies)\n",
    "        idcg_value = idcg(actual_movies, len(recommended_movies))\n",
    "        ndcg = (dcg_value / idcg_value) * 100 if idcg_value > 0 else 0\n",
    "        running_ndcg += ndcg\n",
    "\n",
    "    precision = running_precision / len(recommendations)\n",
    "    recall = running_recall / len(recommendations)\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall)\n",
    "    ndcg = running_ndcg / len(recommendations)\n",
    "\n",
    "    return precision, recall, f_measure, ndcg\n",
    "\n",
    "print(\"Precision \\t%.4f%%\\nRecall \\t\\t%.4f%%\\nF-Measure \\t%.4f%%\\nNDCG \\t\\t%.4f\" % recommendation_performance(top_10_recommendations, test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
