{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  movieId  rating  timestamp\n",
      "55        1     1031     5.0  964982653\n",
      "230       1     4006     4.0  964982903\n",
      "69        1     1197     5.0  964981872\n",
      "168       1     2596     5.0  964981144\n",
      "109       1     1777     4.0  964981230\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_user(ratings, test_size=0.2):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Get all unique users\n",
    "    for user_id in ratings['userId'].unique():\n",
    "        # Filter the dataset to include only rows corresponding to curr user\n",
    "        user_data = ratings[ratings['userId'] == user_id]\n",
    "        # Check if user has rated more than 5 movies to meaningfully split data into train and test\n",
    "        # Ex. user with 10 ratings -> 8 train, 2 test, but user with 3 ratings -> 2 train, 1 test\n",
    "            # In the latter case, we would not have enough data to train the model\n",
    "        # If user has rated more than 5 movies, split the data into train and test\n",
    "        # Else, include all data in train\n",
    "        if len(user_data) >= 5:\n",
    "            train_data, test_data = train_test_split(user_data, test_size=test_size, random_state=42)\n",
    "            train_list.append(train_data)\n",
    "            test_list.append(test_data)\n",
    "        else:\n",
    "            train_list.append(user_data)\n",
    "    \n",
    "    # Combine training and testing data for all users into train and test\n",
    "    train = pd.concat(train_list)\n",
    "    test = pd.concat(test_list)\n",
    "    return train, test\n",
    "\n",
    "train_data, test_data = train_test_split_user(ratings)\n",
    "print(train_data.head())\n",
    "# We don't need timestamp column\n",
    "train_data = train_data.drop(columns=['timestamp'])\n",
    "test_data = test_data.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize(ratings):\n",
    "    # Group by userId\n",
    "    normalized_ratings = ratings.groupby('userId')['rating'].transform(lambda x: quantile_scale(x))\n",
    "    ratings['rating'] = normalized_ratings\n",
    "    return ratings\n",
    "\n",
    "def quantile_scale(ratings):\n",
    "    # Sort ratings and assign ranks\n",
    "    sorted_ratings = np.sort(ratings)\n",
    "    ranks = np.argsort(np.argsort(ratings))  # Get ranks of the original ratings\n",
    "    # Assign the sorted values to original ranks (quantile transformation)\n",
    "    return np.interp(ratings, sorted_ratings, sorted_ratings)\n",
    "train_data = quantile_normalize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['weight'] = train_data.groupby('movieId')['movieId'].transform('count')\n",
    "train_data['weight'] = train_data['weight'] / train_data['weight'].sum()  # Normalize weights\n",
    "train_data = train_data.sample(frac=1, weights=train_data['weight'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_movies = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_movies)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_movies)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            print(\"Iteration: %d ; mae = %.4f ; rmse = %.4f\" % (i+1, self.mae(), self.rmse()))\n",
    "          \n",
    "    def mae(self):\n",
    "        xs, ys = self.R.nonzero() \n",
    "        predicted = self.full_matrix()  \n",
    "        error = 0\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            error += abs(self.R[x, y] - predicted[x, y])  \n",
    "        \n",
    "        return error / len(xs)\n",
    "    \n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "\n",
    "        return np.sqrt(error/len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            P_i = self.P[i, :].copy()\n",
    "            Q_j = self.Q[j, :].copy()\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * Q_j - self.beta * P_i)\n",
    "            self.Q[j, :] += self.alpha * (e * P_i - self.beta * Q_j)\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        m_b = self.b_i[j] if j < len(self.b_i) else 0\n",
    "        l_i = self.Q[j, :].T if j < len(self.Q) else np.mean(self.Q, axis=0) \n",
    "        prediction = self.b + self.b_u[i] + m_b + self.P[i, :].dot(l_i)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 ; mae = 0.7000 ; rmse = 0.8995\n",
      "Iteration: 2 ; mae = 0.6773 ; rmse = 0.8755\n",
      "Iteration: 3 ; mae = 0.6657 ; rmse = 0.8619\n",
      "Iteration: 4 ; mae = 0.6580 ; rmse = 0.8528\n",
      "Iteration: 5 ; mae = 0.6520 ; rmse = 0.8457\n",
      "Iteration: 6 ; mae = 0.6481 ; rmse = 0.8403\n",
      "Iteration: 7 ; mae = 0.6427 ; rmse = 0.8351\n",
      "Iteration: 8 ; mae = 0.6393 ; rmse = 0.8310\n",
      "Iteration: 9 ; mae = 0.6373 ; rmse = 0.8274\n",
      "Iteration: 10 ; mae = 0.6339 ; rmse = 0.8240\n",
      "Iteration: 11 ; mae = 0.6317 ; rmse = 0.8206\n",
      "Iteration: 12 ; mae = 0.6289 ; rmse = 0.8169\n",
      "Iteration: 13 ; mae = 0.6252 ; rmse = 0.8135\n",
      "Iteration: 14 ; mae = 0.6231 ; rmse = 0.8101\n",
      "Iteration: 15 ; mae = 0.6212 ; rmse = 0.8062\n",
      "Iteration: 16 ; mae = 0.6173 ; rmse = 0.8014\n",
      "Iteration: 17 ; mae = 0.6139 ; rmse = 0.7965\n",
      "Iteration: 18 ; mae = 0.6102 ; rmse = 0.7912\n",
      "Iteration: 19 ; mae = 0.6047 ; rmse = 0.7844\n",
      "Iteration: 20 ; mae = 0.5998 ; rmse = 0.7772\n",
      "Iteration: 21 ; mae = 0.5938 ; rmse = 0.7693\n",
      "Iteration: 22 ; mae = 0.5867 ; rmse = 0.7599\n",
      "Iteration: 23 ; mae = 0.5801 ; rmse = 0.7505\n",
      "Iteration: 24 ; mae = 0.5726 ; rmse = 0.7399\n",
      "Iteration: 25 ; mae = 0.5640 ; rmse = 0.7287\n",
      "Iteration: 26 ; mae = 0.5557 ; rmse = 0.7174\n",
      "Iteration: 27 ; mae = 0.5470 ; rmse = 0.7054\n",
      "Iteration: 28 ; mae = 0.5378 ; rmse = 0.6936\n",
      "Iteration: 29 ; mae = 0.5293 ; rmse = 0.6814\n",
      "Iteration: 30 ; mae = 0.5194 ; rmse = 0.6693\n",
      "Iteration: 31 ; mae = 0.5105 ; rmse = 0.6569\n",
      "Iteration: 32 ; mae = 0.5011 ; rmse = 0.6453\n",
      "Iteration: 33 ; mae = 0.4927 ; rmse = 0.6337\n",
      "Iteration: 34 ; mae = 0.4837 ; rmse = 0.6218\n",
      "Iteration: 35 ; mae = 0.4748 ; rmse = 0.6106\n",
      "Iteration: 36 ; mae = 0.4666 ; rmse = 0.5997\n",
      "Iteration: 37 ; mae = 0.4581 ; rmse = 0.5888\n",
      "Iteration: 38 ; mae = 0.4501 ; rmse = 0.5783\n",
      "Iteration: 39 ; mae = 0.4422 ; rmse = 0.5682\n",
      "Iteration: 40 ; mae = 0.4352 ; rmse = 0.5584\n",
      "Iteration: 41 ; mae = 0.4273 ; rmse = 0.5487\n",
      "Iteration: 42 ; mae = 0.4198 ; rmse = 0.5392\n",
      "Iteration: 43 ; mae = 0.4132 ; rmse = 0.5303\n",
      "Iteration: 44 ; mae = 0.4065 ; rmse = 0.5216\n",
      "Iteration: 45 ; mae = 0.3998 ; rmse = 0.5132\n",
      "Iteration: 46 ; mae = 0.3936 ; rmse = 0.5052\n",
      "Iteration: 47 ; mae = 0.3877 ; rmse = 0.4977\n",
      "Iteration: 48 ; mae = 0.3815 ; rmse = 0.4901\n",
      "Iteration: 49 ; mae = 0.3763 ; rmse = 0.4831\n",
      "Iteration: 50 ; mae = 0.3709 ; rmse = 0.4760\n",
      "Iteration: 51 ; mae = 0.3657 ; rmse = 0.4695\n",
      "Iteration: 52 ; mae = 0.3604 ; rmse = 0.4629\n",
      "Iteration: 53 ; mae = 0.3557 ; rmse = 0.4568\n",
      "Iteration: 54 ; mae = 0.3512 ; rmse = 0.4512\n",
      "Iteration: 55 ; mae = 0.3466 ; rmse = 0.4454\n",
      "Iteration: 56 ; mae = 0.3425 ; rmse = 0.4401\n",
      "Iteration: 57 ; mae = 0.3381 ; rmse = 0.4349\n",
      "Iteration: 58 ; mae = 0.3340 ; rmse = 0.4297\n",
      "Iteration: 59 ; mae = 0.3302 ; rmse = 0.4251\n",
      "Iteration: 60 ; mae = 0.3266 ; rmse = 0.4205\n",
      "Iteration: 61 ; mae = 0.3231 ; rmse = 0.4160\n",
      "Iteration: 62 ; mae = 0.3194 ; rmse = 0.4116\n",
      "Iteration: 63 ; mae = 0.3162 ; rmse = 0.4077\n",
      "Iteration: 64 ; mae = 0.3131 ; rmse = 0.4040\n",
      "Iteration: 65 ; mae = 0.3101 ; rmse = 0.4000\n",
      "Iteration: 66 ; mae = 0.3070 ; rmse = 0.3965\n",
      "Iteration: 67 ; mae = 0.3042 ; rmse = 0.3931\n",
      "Iteration: 68 ; mae = 0.3012 ; rmse = 0.3897\n",
      "Iteration: 69 ; mae = 0.2987 ; rmse = 0.3863\n",
      "Iteration: 70 ; mae = 0.2959 ; rmse = 0.3833\n"
     ]
    }
   ],
   "source": [
    "user_ids = train_data['userId'].unique()  \n",
    "movie_ids = train_data['movieId'].unique()  \n",
    "\n",
    "user_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "movie_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "R = np.zeros((len(user_ids), len(movie_ids)))\n",
    "\n",
    "for row in train_data.itertuples():\n",
    "    user_idx = user_to_idx[row.userId]\n",
    "    movie_idx = movie_to_idx[row.movieId]\n",
    "    R[user_idx, movie_idx] = row.rating\n",
    "\n",
    "mf = MF(R, K=50, alpha=0.01, beta=0.05, iterations=70)\n",
    "# Iteration: 178 ; mae = 0.1979 ; rmse = 0.2732\n",
    "\n",
    "mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(mf_model, test_data, user_to_idx, movie_to_idx):\n",
    "    squared_error = 0\n",
    "    absolute_error = 0\n",
    "    n = len(test_data)\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        uid = int(row['userId'])\n",
    "        mid = int(row['movieId'])\n",
    "             \n",
    "        user_id = int(user_to_idx[uid])\n",
    "        movie_id = int(movie_to_idx[mid]) if mid in movie_to_idx else len(movie_to_idx)\n",
    "        actual_rating = row['rating']\n",
    "        \n",
    "        predicted_rating = mf_model.get_rating(user_id, movie_id)\n",
    "        \n",
    "        squared_error += (actual_rating - predicted_rating) ** 2\n",
    "        \n",
    "        absolute_error += abs(actual_rating - predicted_rating)\n",
    "    \n",
    "    rmse = np.sqrt(squared_error / n)\n",
    "    mae = absolute_error / n\n",
    "\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.861073144598252\n",
      "Test MAE: 0.6592905696029188\n"
     ]
    }
   ],
   "source": [
    "rmse, mae = test_model(mf, test_data, user_to_idx, movie_to_idx)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwatched_movies(ratings):\n",
    "    all_movie_ids = set(ratings['movieId'])\n",
    "    user_to_unwatched_movies = {}\n",
    "\n",
    "    for user_id in ratings['userId'].unique():\n",
    "        user = ratings[ratings['userId'] == user_id]\n",
    "        watched_movies = set(user['movieId'])\n",
    "        unwatched_movies = all_movie_ids - watched_movies\n",
    "        user_to_unwatched_movies[user_id] = unwatched_movies\n",
    "\n",
    "    return user_to_unwatched_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(mf_model, user_to_idx, movie_to_idx, n=10):\n",
    "    unwatched = unwatched_movies(train_data)\n",
    "    recommendations = {}\n",
    "\n",
    "    for user_id in user_to_idx.keys():\n",
    "        user_idx = user_to_idx[user_id]\n",
    "        predictions = mf_model.full_matrix()[user_idx]\n",
    "        recommended_movie_idxs = np.argsort(predictions)[::-1]\n",
    "        recommended_movies = [k for k, v in movie_to_idx.items() if v in recommended_movie_idxs and k in unwatched[user_id]][:n]\n",
    "        recommendations[user_id] = recommended_movies\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "top_10_recommendations = recommend_movies(mf, user_to_idx, movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_recommend_movies(mf_model, user_to_idx, movie_to_idx, train_data, n=10, \n",
    "                            user_rating_threshold=None, min_ratings=10, popularity_weight=0.4, confidence_weight=0.3):\n",
    "    \"\"\"\n",
    "    Enhanced recommendation function with multiple improvements:\n",
    "    1. Considers movie popularity and rating distribution\n",
    "    2. Filters out movies with too few ratings\n",
    "    3. Uses rating threshold to determine \"liked\" movies\n",
    "    4. Implements candidate selection\n",
    "    \"\"\"\n",
    "    # Calculate movie statistics\n",
    "    movie_stats = train_data.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean', 'std']\n",
    "    }).droplevel(0, axis=1)\n",
    "    \n",
    "    # Filter movies with enough ratings\n",
    "    valid_movies = set(movie_stats[movie_stats['count'] >= min_ratings].index)\n",
    "    \n",
    "    if user_rating_threshold is None:\n",
    "        user_rating_threshold = {}\n",
    "        for user_id in train_data['userId'].unique():\n",
    "            user_ratings = train_data[train_data['userId'] == user_id]\n",
    "            # user_rating_threshold[user_id] = user_ratings['rating'].median()\n",
    "            user_rating_threshold[user_id] = user_ratings['rating'].mean() + 0.5 * user_ratings['rating'].std()\n",
    "\n",
    "    # Calculate user preferences\n",
    "    user_preferences = {}\n",
    "    for user_id in train_data['userId'].unique():\n",
    "        user_ratings = train_data[train_data['userId'] == user_id]\n",
    "        liked_movies = user_ratings[user_ratings['rating'] >= user_rating_threshold[user_id]]['movieId']\n",
    "        \n",
    "        if len(liked_movies) > 0:\n",
    "            # Get genres or other features of liked movies\n",
    "            user_preferences[user_id] = liked_movies.tolist()\n",
    "            \n",
    "    \n",
    "    unwatched = unwatched_movies(train_data)\n",
    "    recommendations = {}\n",
    "    \n",
    "    for user_id in user_to_idx.keys():\n",
    "        if user_id not in user_preferences:\n",
    "            continue\n",
    "            \n",
    "        user_idx = user_to_idx[user_id]\n",
    "        user_unwatched = unwatched[user_id].intersection(valid_movies)\n",
    "        \n",
    "        if not user_unwatched:\n",
    "            continue\n",
    "            \n",
    "        # Get predictions for unwatched movies\n",
    "        predictions = []\n",
    "        for movie_id in user_unwatched:\n",
    "            if movie_id in movie_to_idx:\n",
    "                movie_idx = movie_to_idx[movie_id]\n",
    "                pred_rating = mf_model.get_rating(user_idx, movie_idx)\n",
    "                \n",
    "                # Calculate confidence score based on number of ratings\n",
    "                confidence = 1 - (1 / (1 + movie_stats.loc[movie_id, 'count'] / 100))\n",
    "                \n",
    "                # Calculate popularity score normalized between 0 and 1\n",
    "                popularity = movie_stats.loc[movie_id, 'count'] / movie_stats['count'].max()\n",
    "                \n",
    "                # Combine prediction with confidence and popularity\n",
    "                adjusted_score = ((1 - popularity_weight - confidence_weight) * pred_rating + \n",
    "                                confidence_weight * confidence + \n",
    "                                popularity_weight * popularity)\n",
    "                \n",
    "                predictions.append((movie_id, adjusted_score))\n",
    "        \n",
    "        # Sort by adjusted score and get top N\n",
    "        recommendations[user_id] = [\n",
    "            movie_id for movie_id, _ in \n",
    "            sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "        ]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "top_10_recommendations = enhanced_recommend_movies(mf, user_to_idx, movie_to_idx, train_data, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision \t6.0492%\n",
      "Recall \t\t2.2724%\n",
      "F-Measure \t3.3038%\n",
      "NDCG \t\t0.0560\n"
     ]
    }
   ],
   "source": [
    "def dcg(recommended_movies, actual_movies):\n",
    "    dcg_value = 0.0\n",
    "    for i, movie in enumerate(recommended_movies):\n",
    "        if movie in actual_movies:\n",
    "            dcg_value += 1 / np.log2(i + 2)  \n",
    "    return dcg_value\n",
    "\n",
    "def idcg(actual_movies, length):\n",
    "    idcg_value = 0.0\n",
    "    for i in range(min(len(actual_movies), length)):\n",
    "        idcg_value += 1 / np.log2(i + 2)\n",
    "    return idcg_value\n",
    "\n",
    "def recommendation_performance(recommendations, test_data):\n",
    "    running_precision, running_recall, running_ndcg = 0, 0, 0\n",
    "\n",
    "    for user_id, recommended_movies in recommendations.items():\n",
    "        actual_movies = test_data[test_data['userId'] == user_id]['movieId']\n",
    "\n",
    "        intersection = len(set(recommended_movies) & set(actual_movies))\n",
    "        precision = (intersection / len(recommended_movies)) * 100\n",
    "        recall = (intersection / len(actual_movies)) * 100\n",
    "\n",
    "        running_precision += precision\n",
    "        running_recall += recall\n",
    "\n",
    "        dcg_value = dcg(list(recommended_movies), list(actual_movies))\n",
    "        idcg_value = idcg(list(actual_movies), len(recommended_movies))\n",
    "        ndcg = dcg_value / idcg_value if idcg_value > 0 else 0\n",
    "        running_ndcg += ndcg\n",
    "\n",
    "    precision = running_precision / len(recommendations)\n",
    "    recall = running_recall / len(recommendations)\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall)\n",
    "    ndcg = running_ndcg / len(recommendations)\n",
    "\n",
    "    return precision, recall, f_measure, ndcg\n",
    "\n",
    "print(\"Precision \\t%.4f%%\\nRecall \\t\\t%.4f%%\\nF-Measure \\t%.4f%%\\nNDCG \\t\\t%.4f\" % recommendation_performance(top_10_recommendations, test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_sci_439",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
