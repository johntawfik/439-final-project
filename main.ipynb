{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  movieId  rating  timestamp\n",
      "55        1     1031     5.0  964982653\n",
      "230       1     4006     4.0  964982903\n",
      "69        1     1197     5.0  964981872\n",
      "168       1     2596     5.0  964981144\n",
      "109       1     1777     4.0  964981230\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_user(ratings, test_size=0.2):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Get all unique users\n",
    "    for user_id in ratings['userId'].unique():\n",
    "        # Filter the dataset to include only rows corresponding to curr user\n",
    "        user_data = ratings[ratings['userId'] == user_id]\n",
    "        # Check if user has rated more than 5 movies to meaningfully split data into train and test\n",
    "        # Ex. user with 10 ratings -> 8 train, 2 test, but user with 3 ratings -> 2 train, 1 test\n",
    "            # In the latter case, we would not have enough data to train the model\n",
    "        # If user has rated more than 5 movies, split the data into train and test\n",
    "        # Else, include all data in train\n",
    "        if len(user_data) >= 5:\n",
    "            train_data, test_data = train_test_split(user_data, test_size=test_size, random_state=42)\n",
    "            train_list.append(train_data)\n",
    "            test_list.append(test_data)\n",
    "        else:\n",
    "            train_list.append(user_data)\n",
    "    \n",
    "    # Combine training and testing data for all users into train and test\n",
    "    train = pd.concat(train_list)\n",
    "    test = pd.concat(test_list)\n",
    "    return train, test\n",
    "\n",
    "train_data, test_data = train_test_split_user(ratings)\n",
    "print(train_data.head())\n",
    "# We don't need timestamp column\n",
    "train_data = train_data.drop(columns=['timestamp'])\n",
    "test_data = test_data.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize(ratings):\n",
    "    # Group by userId\n",
    "    normalized_ratings = ratings.groupby('userId')['rating'].transform(lambda x: quantile_scale(x))\n",
    "    ratings['rating'] = normalized_ratings\n",
    "    return ratings\n",
    "\n",
    "def quantile_scale(ratings):\n",
    "    # Sort ratings and assign ranks\n",
    "    sorted_ratings = np.sort(ratings)\n",
    "    ranks = np.argsort(np.argsort(ratings))  # Get ranks of the original ratings\n",
    "    # Assign the sorted values to original ranks (quantile transformation)\n",
    "    return np.interp(ratings, sorted_ratings, sorted_ratings)\n",
    "train_data = quantile_normalize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['weight'] = train_data.groupby('movieId')['movieId'].transform('count')\n",
    "train_data['weight'] = train_data['weight'] / train_data['weight'].sum()  # Normalize weights\n",
    "train_data = train_data.sample(frac=1, weights=train_data['weight'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_movies = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_movies, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_movies)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_movies)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            print(\"Iteration: %d ; mae = %.4f ; rmse = %.4f\" % (i+1, self.mae(), self.rmse()))\n",
    "          \n",
    "    def mae(self):\n",
    "        xs, ys = self.R.nonzero() \n",
    "        predicted = self.full_matrix()  \n",
    "        error = 0\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            error += abs(self.R[x, y] - predicted[x, y])  \n",
    "        \n",
    "        return error / len(xs)\n",
    "    \n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "\n",
    "        return np.sqrt(error/len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            P_i = self.P[i, :].copy()\n",
    "            Q_j = self.Q[j, :].copy()\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * Q_j - self.beta * P_i)\n",
    "            self.Q[j, :] += self.alpha * (e * P_i - self.beta * Q_j)\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        m_b = self.b_i[j] if j < len(self.b_i) else 0\n",
    "        l_i = self.Q[j, :].T if j < len(self.Q) else np.mean(self.Q, axis=0) \n",
    "        prediction = self.b + self.b_u[i] + m_b + self.P[i, :].dot(l_i)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 ; mae = 0.6996 ; rmse = 0.8993\n",
      "Iteration: 2 ; mae = 0.6775 ; rmse = 0.8751\n",
      "Iteration: 3 ; mae = 0.6653 ; rmse = 0.8618\n",
      "Iteration: 4 ; mae = 0.6581 ; rmse = 0.8529\n",
      "Iteration: 5 ; mae = 0.6519 ; rmse = 0.8457\n",
      "Iteration: 6 ; mae = 0.6469 ; rmse = 0.8400\n",
      "Iteration: 7 ; mae = 0.6432 ; rmse = 0.8350\n",
      "Iteration: 8 ; mae = 0.6395 ; rmse = 0.8311\n",
      "Iteration: 9 ; mae = 0.6365 ; rmse = 0.8270\n",
      "Iteration: 10 ; mae = 0.6345 ; rmse = 0.8240\n",
      "Iteration: 11 ; mae = 0.6319 ; rmse = 0.8205\n",
      "Iteration: 12 ; mae = 0.6292 ; rmse = 0.8170\n",
      "Iteration: 13 ; mae = 0.6264 ; rmse = 0.8138\n",
      "Iteration: 14 ; mae = 0.6238 ; rmse = 0.8104\n",
      "Iteration: 15 ; mae = 0.6206 ; rmse = 0.8070\n",
      "Iteration: 16 ; mae = 0.6181 ; rmse = 0.8024\n",
      "Iteration: 17 ; mae = 0.6147 ; rmse = 0.7975\n",
      "Iteration: 18 ; mae = 0.6109 ; rmse = 0.7923\n",
      "Iteration: 19 ; mae = 0.6055 ; rmse = 0.7860\n",
      "Iteration: 20 ; mae = 0.6002 ; rmse = 0.7787\n",
      "Iteration: 21 ; mae = 0.5945 ; rmse = 0.7708\n",
      "Iteration: 22 ; mae = 0.5883 ; rmse = 0.7617\n",
      "Iteration: 23 ; mae = 0.5812 ; rmse = 0.7518\n",
      "Iteration: 24 ; mae = 0.5732 ; rmse = 0.7411\n",
      "Iteration: 25 ; mae = 0.5657 ; rmse = 0.7304\n",
      "Iteration: 26 ; mae = 0.5563 ; rmse = 0.7185\n",
      "Iteration: 27 ; mae = 0.5473 ; rmse = 0.7063\n",
      "Iteration: 28 ; mae = 0.5386 ; rmse = 0.6941\n",
      "Iteration: 29 ; mae = 0.5290 ; rmse = 0.6820\n",
      "Iteration: 30 ; mae = 0.5200 ; rmse = 0.6697\n",
      "Iteration: 31 ; mae = 0.5103 ; rmse = 0.6572\n",
      "Iteration: 32 ; mae = 0.5010 ; rmse = 0.6449\n",
      "Iteration: 33 ; mae = 0.4922 ; rmse = 0.6331\n",
      "Iteration: 34 ; mae = 0.4831 ; rmse = 0.6216\n",
      "Iteration: 35 ; mae = 0.4744 ; rmse = 0.6101\n"
     ]
    }
   ],
   "source": [
    "user_ids = train_data['userId'].unique()  \n",
    "movie_ids = train_data['movieId'].unique()  \n",
    "\n",
    "user_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "movie_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "R = np.zeros((len(user_ids), len(movie_ids)))\n",
    "\n",
    "for row in train_data.itertuples():\n",
    "    user_idx = user_to_idx[row.userId]\n",
    "    movie_idx = movie_to_idx[row.movieId]\n",
    "    R[user_idx, movie_idx] = row.rating\n",
    "\n",
    "mf = MF(R, K=50, alpha=0.01, beta=0.05, iterations=35)\n",
    "# Iteration: 178 ; mae = 0.1979 ; rmse = 0.2732\n",
    "\n",
    "mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(mf_model, test_data, user_to_idx, movie_to_idx):\n",
    "    squared_error = 0\n",
    "    absolute_error = 0\n",
    "    n = len(test_data)\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        uid = int(row['userId'])\n",
    "        mid = int(row['movieId'])\n",
    "             \n",
    "        user_id = int(user_to_idx[uid])\n",
    "        movie_id = int(movie_to_idx[mid]) if mid in movie_to_idx else len(movie_to_idx)\n",
    "        actual_rating = row['rating']\n",
    "        \n",
    "        predicted_rating = mf_model.get_rating(user_id, movie_id)\n",
    "        \n",
    "        squared_error += (actual_rating - predicted_rating) ** 2\n",
    "        \n",
    "        absolute_error += abs(actual_rating - predicted_rating)\n",
    "    \n",
    "    rmse = np.sqrt(squared_error / n)\n",
    "    mae = absolute_error / n\n",
    "\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8514362670563544\n",
      "Test MAE: 0.6526266546199773\n"
     ]
    }
   ],
   "source": [
    "rmse, mae = test_model(mf, test_data, user_to_idx, movie_to_idx)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwatched_movies(ratings):\n",
    "    all_movie_ids = set(ratings['movieId'])\n",
    "    user_to_unwatched_movies = {}\n",
    "\n",
    "    for user_id in ratings['userId'].unique():\n",
    "        user = ratings[ratings['userId'] == user_id]\n",
    "        watched_movies = set(user['movieId'])\n",
    "        unwatched_movies = all_movie_ids - watched_movies\n",
    "        user_to_unwatched_movies[user_id] = unwatched_movies\n",
    "\n",
    "    return user_to_unwatched_movies\n",
    "\n",
    "def recommend_movies(mf_model, user_to_idx, movie_to_idx, n=10):\n",
    "    unwatched = unwatched_movies(train_data)\n",
    "    recommendations = {}\n",
    "\n",
    "    for user_id in user_to_idx.keys():\n",
    "        user_idx = user_to_idx[user_id]\n",
    "        predictions = mf_model.full_matrix()[user_idx]\n",
    "        recommended_movie_idxs = np.argsort(predictions)[::-1]\n",
    "        recommended_movies = [k for k, v in movie_to_idx.items() if v in recommended_movie_idxs and k in unwatched[user_id]][:n]\n",
    "        recommendations[user_id] = recommended_movies\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "top_10_recommendations = recommend_movies(mf, user_to_idx, movie_to_idx, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision \t6.0492%\n",
      "Recall \t\t2.2724%\n",
      "F-Measure \t3.3038%\n",
      "NDCG \t\t0.0000\n"
     ]
    }
   ],
   "source": [
    "def dcg(recommended_movies, actual_movies):\n",
    "    dcg_value = 0.0\n",
    "    for i, movie in enumerate(recommended_movies):\n",
    "        if movie in actual_movies:\n",
    "            dcg_value += 1 / np.log2(i + 2)  \n",
    "    return dcg_value\n",
    "\n",
    "def idcg(actual_movies, length):\n",
    "    idcg_value = 0.0\n",
    "    for i in range(min(len(actual_movies), length)):\n",
    "        idcg_value += 1 / np.log2(i + 2)\n",
    "    return idcg_value\n",
    "\n",
    "def recommendation_performance(recommendations, test_data):\n",
    "    running_precision, running_recall, running_ndcg = 0, 0, 0\n",
    "\n",
    "    for user_id, recommended_movies in recommendations.items():\n",
    "        actual_movies = test_data[test_data['userId'] == user_id]['movieId']\n",
    "\n",
    "        intersection = len(set(recommended_movies) & set(actual_movies))\n",
    "        precision = (intersection / len(recommended_movies)) * 100\n",
    "        recall = (intersection / len(actual_movies)) * 100\n",
    "\n",
    "        running_precision += precision\n",
    "        running_recall += recall\n",
    "\n",
    "        dcg_value = dcg(recommended_movies, actual_movies)\n",
    "        idcg_value = idcg(actual_movies, len(recommended_movies))\n",
    "        ndcg = (dcg_value / idcg_value) * 100 if idcg_value > 0 else 0\n",
    "        running_ndcg += ndcg\n",
    "\n",
    "    precision = running_precision / len(recommendations)\n",
    "    recall = running_recall / len(recommendations)\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall)\n",
    "    ndcg = running_ndcg / len(recommendations)\n",
    "\n",
    "    return precision, recall, f_measure, ndcg\n",
    "\n",
    "print(\"Precision \\t%.4f%%\\nRecall \\t\\t%.4f%%\\nF-Measure \\t%.4f%%\\nNDCG \\t\\t%.4f\" % recommendation_performance(top_10_recommendations, test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
